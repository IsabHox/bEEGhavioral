{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0237f4b",
   "metadata": {},
   "source": [
    "# Combining behavioral and neurophysiological data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32fdff40",
   "metadata": {},
   "source": [
    "The goal of this workshop is to introduce a way of combining neurophysiological data and behavioral observations, on recordings of human EEG in a discrimination task. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0cf5917",
   "metadata": {},
   "source": [
    "## 1. Description of the experiment and data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "62177864",
   "metadata": {},
   "source": [
    "In this task, participants were presented at each trial either with an image of a face or a sound, and had to report what they have perceived through key presses (left arrow=sound, right arrow=face) as fast and accuately as possible. A timeout on response time would occur two seconds after stimulus presentation. \n",
    "\n",
    "The experiment is split into two parts:\n",
    "- a calibration phase, where the stimuli were preceded by a predictive cue, i.e. a stimulus to which participants did not have to response, but that predicted with a 80% accuracy the stimulus that is coming next\n",
    "- a test phase, whose sequence does not include cues.\n",
    "\n",
    "While performing this task, their EEG activity was recorded using 32 channels (including a reference, located in Fz), along with their response class and time. All information is contained in the EEG recording, that tracks all that happens and when it happens (EEG activity and experiment events). The experiment events are encoded as \"markers\", and are each associated with a type-specific number.\n",
    "\n",
    "The experiment goes as follows:\n",
    "\n",
    "<img alt='Paradigm' align='left' width=1116.0 height=828.0 src=https://raw.githubusercontent.com/IsabHox/bEEGhavioral/main/paradigm.png>\n",
    "\n",
    "During the red cross, participants can blink and move slightly. They are instructed to start focusing as soon as the white cross is displayed, and they are presented with a cue after a few seconds (between 1.5 and 3). This cue is either the image of an eye or an ear, and it predicts with ~80% accuracy the stimulus that is coming next (eye->face image, ear->sound).\n",
    "\n",
    "You can find below a list of the possible markers you will find in data:\n",
    "\n",
    "|Marker|Event description|\n",
    "|:-:|:-:|\n",
    "|1|Cue \"eye\" is presented|\n",
    "|2|Cue \"ear\" is presented|\n",
    "|8|Trial is strating, red cross appearing|\n",
    "|9|White cross appearing|\n",
    "|11|Stimulus \"face\" is presented|\n",
    "|12|Stimulus \"sound\" is presented|\n",
    "|14|Block starts|\n",
    "|1001|Participant answers \"right\" (ie \"face\")|\n",
    "|1002|Participant answers \"left\" (ie \"sound\")|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb95a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports and utility functions\n",
    "import numpy as np\n",
    "import mne\n",
    "import matplotlib.pyplot as plt\n",
    "import mne\n",
    "from collections import Counter\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ef1b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% import and preprocessing\n",
    "def import_raw(datapath,nblock):\n",
    "    '''Imports raw data as an MNE structure.\n",
    "    Input: datapath (str) path to reach data files.\n",
    "    Ouput: eegdata (MNE.Raw) relevant data'''\n",
    "    eegdatas=[0 for i in range(nblock)]\n",
    "    for b in range (nblock):\n",
    "        filename=datapath.format(b+1)\n",
    "        vhdr_fname=filename+'.vhdr';\n",
    "        eegdatas[b]=mne.io.read_raw_brainvision(vhdr_fname,preload=True)\n",
    "        \n",
    "    eegdata=mne.concatenate_raws(eegdatas,preload=True)\n",
    "    montage1020 = mne.channels.make_standard_montage('standard_1020')\n",
    "    eegdata = eegdata.set_montage(montage1020)\n",
    "    return eegdata\n",
    "\n",
    "def get_rej_trials(drop_log):\n",
    "    '''From a drop log, get the index of trials that have been rejected'''\n",
    "    ix_list=[]\n",
    "    for i,t in enumerate(drop_log):\n",
    "        if len(t)!=0:\n",
    "            ix_list.append(i)\n",
    "    return ix_list\n",
    "\n",
    "def get_bad_stats(drop_log):\n",
    "    scores = Counter([ch for d in drop_log for ch in d])\n",
    "    return scores\n",
    "\n",
    "def get_bad_channels_trials(eegdata,event_id,thresh_trial=110e-6,thresh_chans=0.15,tmin=-1,tmax=3,reject_tmin=-0.9,reject_tmax=0.5):\n",
    "    '''Returns bad channels and trials given the specified thresholds.\n",
    "    Inputs:\n",
    "        thresh_trial: (default 100e-6) threshold value from which an epoch should be rejected (in V)\n",
    "        thresh_chans: (default 0.15) proportion of trials rejected to decide to reject channels. Should be between 0 and 1\n",
    "    Outputs:\n",
    "        rej_trials: list of trial indices that should be rejected\n",
    "        rej_channels: list of str of the rejected channels'''\n",
    "        \n",
    "    all_evt,evt_dict=mne.events_from_annotations(eegdata)\n",
    "    stim_ix=np.where((all_evt[:,2]==event_id[0]) | (all_evt[:,2]==event_id[1]))[0]\n",
    "    events=all_evt[stim_ix,:]\n",
    "    \n",
    "    rej_dict=dict(eeg=thresh_trial)\n",
    "    ep = mne.Epochs(eegdata, events, baseline=None,tmin=tmin, tmax=tmax,reject=rej_dict,reject_tmin=reject_tmin,reject_tmax=reject_tmax, preload=True)\n",
    "    drop_log=list(ep.drop_log)\n",
    "    stats=len(get_rej_trials(drop_log))/len(events) #ep.drop_log_stats()\n",
    "    stat_details=get_bad_stats(drop_log)\n",
    "    rej_trials=get_rej_trials(drop_log)\n",
    "    rej_channels=[]\n",
    "    ch=0\n",
    "    while stats>thresh_chans and ch<eegdata.info['nchan']:\n",
    "        chan_to_rej=stat_details.most_common()[0][0]\n",
    "        rej_channels.extend([chan_to_rej])\n",
    "        for i in range(len(drop_log)):\n",
    "            if chan_to_rej in drop_log[i]:\n",
    "                new_log=list(drop_log[i])\n",
    "                new_log.remove(chan_to_rej)\n",
    "                if new_log is None:\n",
    "                    drop_log[i]=()\n",
    "                else:\n",
    "                    drop_log[i]=tuple(new_log)\n",
    "        stats=len(get_rej_trials(drop_log))/len(events)\n",
    "        stat_details=get_bad_stats(drop_log)\n",
    "        ch+=1\n",
    "    rej_trials=get_rej_trials(drop_log)\n",
    "    return rej_trials,rej_channels\n",
    "\n",
    "def get_epochs(eegdata,event_id,tmin,tmax):\n",
    "    events, event_dict = mne.events_from_annotations(eegdata)\n",
    "    evt_ix=np.where(events[:,2]==event_id[0])\n",
    "    for ix in range(1,len(event_id)):\n",
    "        evt_ix=np.hstack((evt_ix, np.where(events[:,2]==event_id[ix])))\n",
    "    stim_events=np.squeeze(events[evt_ix])\n",
    "    stim_events=np.sort(stim_events.view('int,int,int'), order=['f1'], axis=0).view(np.int)\n",
    "\n",
    "    metadata = {'event_time': stim_events[:, 0],\n",
    "                'trial_number': range(len(stim_events))}#\n",
    "    metadata = pd.DataFrame(metadata)\n",
    "    \n",
    "    epochs = mne.Epochs(eegdata, stim_events, event_id, tmin, tmax, proj=True, baseline=None, metadata=metadata, detrend=0, preload=True,event_repeated='merge')\n",
    "    return epochs\n",
    "\n",
    "\n",
    "#%% plotting functions\n",
    "def plot_ERP(epochs,events):\n",
    "    for e in events:\n",
    "        ev=epochs[e].average()\n",
    "        ev.plot_joint(title=e)\n",
    "    all_ev=epochs.average()\n",
    "    all_ev.plot_joint(title='All conditions')\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "200ec18f",
   "metadata": {},
   "source": [
    "## 2. Import and visualize data\n",
    "In this first part we look at raw data and see how we can improve it.\n",
    "\n",
    "First of all, you need to download the data at the [following link](https://cirrus.universite-paris-saclay.fr/s/xPP3rzEgPFTEb5R). Put it in a folder on your computer, and copy its path next to the \"my_path\" variable in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512c62a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import raw data\n",
    "my_path=... #COMPLETE HERE WITH YOUR PATH to the data\n",
    "datapath=my_path+'959_calib_000{}'\n",
    "#datapath_test=my_path+'959_test_000{}'\n",
    "nblocks=4\n",
    "nblocks_test=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaed5da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "eegdata=import_raw(datapath,nblocks)\n",
    "\n",
    "# plot electrode location\n",
    "eegdata.plot_sensors(show_names=True)\n",
    "\n",
    "# epoch data\n",
    "events=[11,12]\n",
    "tmin=-1\n",
    "tmax=0.5\n",
    "epochs=get_epochs(eegdata, events,tmin=tmin, tmax=tmax)\n",
    "\n",
    "# plot ERP\n",
    "plot_ERP(epochs,['11','12'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac564b4a",
   "metadata": {},
   "source": [
    "We can see that the data is quite messy, as it is prone to artifacts. In fact, with EEG, any small movement can appear in the signal, from blinking, to sweating, to clenching the jaw. It is necessary to remove them. Run the code below to see how this is improved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e954ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter data out\n",
    "fmin=None\n",
    "fmax=30\n",
    "eegdata_filtered=eegdata.filter(fmin, fmax, fir_design='firwin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982115e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reject outliers that cannot be filtered\n",
    "#first, we can check if some electrodes have too high impedances\n",
    "def get_bad_impedance(eegdata, thresh=50):\n",
    "    '''Adds a \"bad\" flag to channels whose impedance is beyond the specified threshold (specified in kOhm).\n",
    "    Acts in place (ie modifies the input)'''\n",
    "    impedances=eegdata.impedances.copy()\n",
    "    del impedances['Ref']\n",
    "    #loop over all impedances and extract these whose impedance is either NaN or over the threshold\n",
    "    for i in impedances:\n",
    "        if ... or ...: ################################################\n",
    "            eegdata.info['bads'].extend([i])\n",
    "            \n",
    "get_bad_impedance(eegdata_filtered)\n",
    "print(eegdata_filtered.info['bads'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7fa5a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#then we reject epochs and electrodes that are above a certain threshold \n",
    "rejt,rejc=get_bad_channels_trials(eegdata_filtered,events)\n",
    "eegdata_filtered.info['bads'].extend(rejc)\n",
    "eegdata_filtered = eegdata_filtered.copy().interpolate_bads(reset_bads=False)\n",
    "print(eegdata_filtered.info['bads'])\n",
    "\n",
    "#plot new ERP\n",
    "clean_epochs=get_epochs(eegdata_filtered, events,tmin=tmin, tmax=tmax)\n",
    "clean_epochs.drop(rejt)\n",
    "\n",
    "plot_ERP(clean_epochs,['11','12'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0db8c8",
   "metadata": {},
   "source": [
    "This is already much better. Pre-processing is a whole topic to itself, so we will not go into detail in that part, you have the whole master to learn it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e63c46f",
   "metadata": {},
   "source": [
    "## 3. Look at the behavior\n",
    "We are not only interested in the EEG, but also in how the participants behaved and in particular how fast they responsed. In the following section, we extract the response times and look at their distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df39ac35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract response times\n",
    "def get_RT(eegdata, stim_labels, resp_labels, rejected=[]):\n",
    "    '''Extract response times from markers in EEG recordings, given the labels of the stimulus and the labels of the response.\n",
    "    Inputs:\n",
    "        - eegdata: mne.io.Raw instance\n",
    "        - stim_labels: list of stimulus labels\n",
    "        - resp_labels: list of response labels\n",
    "        - rejected (default []): list of trials to be rejected\n",
    "    Output:\n",
    "        - RT: list of response times'''\n",
    "    events, event_dict= mne.events_from_annotations(eegdata)\n",
    "    subevt_ix=np.where((events[:,2]==stim_labels[0]) | (events[:,2]==stim_labels[1])| (events[:,2]==resp_labels[0])| (events[:,2]==resp_labels[1])| (events[:,2]==resp_labels[2]))[0]\n",
    "    stim_ix=np.where((events[:,2]==stim_labels[0]) | (events[:,2]==stim_labels[1]))[0]\n",
    "    if len(rejected)!=0:\n",
    "        stim_ix=np.delete(stim_ix,rejected)\n",
    "    _,which_timings,_=np.intersect1d(subevt_ix, stim_ix, return_indices=True)\n",
    "    stim_and_resp_events=events[subevt_ix,0]\n",
    "    RT=np.diff(stim_and_resp_events)\n",
    "    RT=RT[which_timings]\n",
    "    return RT\n",
    "\n",
    "responses=[1001,1002,1003]\n",
    "RT=get_RT(eegdata_filtered, events, responses, rejt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26db93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract labels\n",
    "def get_labels(epochs):\n",
    "    '''Extract labels of epochs'''\n",
    "    evt_sorted=np.sort(epochs.events.view('int,int,int'), order=['f1'], axis=0).view(np.int)\n",
    "    labels = evt_sorted[:, -1]\n",
    "    return labels\n",
    "labels=get_labels(clean_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac22d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot histograms\n",
    "plt.figure()\n",
    "plt.hist(RT[labels==11],alpha=0.2,label='Visual, mean={:.0f} ms'.format(np.mean(RT[labels==11])))\n",
    "plt.hist(RT[labels==12],alpha=0.2,label='Auditory, mean={:.0f} ms'.format(np.mean(RT[labels==12])))\n",
    "plt.title('Histogramm of response times, mean={:.0f} ms'.format(np.mean(RT)))\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d85f77",
   "metadata": {},
   "source": [
    "We can also gain insight from the errors that people have made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6249c9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count number of errors\n",
    "def get_errors(eegdata, stim_labels, resp_labels, rejected=[]):\n",
    "    '''Returns a list of binary labels, where 1 indicates that the participant did not provide the right response\n",
    "    Inputs:\n",
    "        - eegdata: mne.io.Raw instance\n",
    "        - stim_labels: list of stimulus labels\n",
    "        - resp_labels: list of response labels\n",
    "        - rejected (default []): list of trials to reject\n",
    "    Output:\n",
    "        -errors: binary list (n_trials) indicating error trials'''\n",
    "    events, event_dict= mne.events_from_annotations(eegdata)\n",
    "    responses=events[np.where((events[:,2]==resp_labels[0])| (events[:,2]==resp_labels[1])| (events[:,2]==resp_labels[2]))[0],2]-1000\n",
    "    stimuli=events[np.where((events[:,2]==stim_labels[0]) | (events[:,2]==stim_labels[1]))[0],2]-10\n",
    "    #Complete the following line. Errors are when the response label do not match the stimulus label\n",
    "    errors=...############################################\n",
    "    return errors\n",
    "\n",
    "errors=get_errors(eegdata_filtered, events,responses,rejt)\n",
    "print('This participant committed {} errors'.format(np.sum(errors)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf140203",
   "metadata": {},
   "source": [
    "## 4. Combining brain activity and other quantitative data: wITPC\n",
    "From the ITPC exists a derived quantity called weighted ITPC, which allows to put in relation the EEG and another quantity: response times, pupil diameter, heart rate, etc. It is particularly useful for putting in relation behavior and phases, and is an elegant alternative to correlations.\n",
    "\n",
    "The first thing we have to do is compute the phase. There are again several ways of doing that, but here what we do is apply a Hilbert transform. What that does is transform the signal into its analytical form, that is each sample becomes written as a complex number: $a+ib$. From this signal, we can extract the power as: $P=a^2+b^2$ and the phase as $\\phi = arctan(\\frac{b}{a})$. \n",
    "\n",
    "Of course, we want to do that for each frequency band separately. In the brain, each frequency band has its own function, and it is therefore relevant to compute the phases separately. We do that by band-pass filtering the signal\n",
    "\n",
    "In which order should we do the operations? With filtering, we have seen that it makes sense to filter the whole signal before cutting it, as edge artifacts can occur. So the steps go as follows:\n",
    "1. Filter raw data in the band of interest\n",
    "2. Compute Hilbert transform\n",
    "3. Epoch data (don't forget to remove the bad channels and trials)\n",
    "4. Compute the phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc890de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_phase(glob_eegdata, freq_band, events, tmin, tmax, rejt=[]):\n",
    "    eegdata=glob_eegdata.copy()\n",
    "    eegdata.filter(freqs[f][0], freqs[f][1], fir_design='firwin')\n",
    "    #then, apply hilbert transform\n",
    "    eegdata.apply_hilbert()\n",
    "    #now, epoch data in the relevant period and extract data\n",
    "    ep=get_epochs(eegdata,events,tmin,tmax)\n",
    "    ep.drop(rejt)\n",
    "    my_data=ep.get_data()\n",
    "    #finally, compute phases from my_data.real and my_data.imag: use the function np.arctan2()\n",
    "    phases= ...#####################################\n",
    "    return phases\n",
    "\n",
    "freqs={'delta':[1,4],\n",
    "       'theta':[4,8],\n",
    "       'alpha':[8,12],\n",
    "       'beta':[12,25]}\n",
    "\n",
    "phases={}\n",
    "\n",
    "for f in freqs:\n",
    "    phases[f]=compute_phase(eegdata, freqs[f], events, tmin, tmax, rejt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa43fa14",
   "metadata": {},
   "source": [
    "Have a look at the maximum and minimum of the phase, what do you notice?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43bb01e5",
   "metadata": {},
   "source": [
    "In fact, the phase is periodic: it varies between $-\\pi$ and $\\pi$, and has a periodicity of $2\\pi$, which means that $-\\pi = \\pi$, and $0=2\\pi$ etc. \n",
    "\n",
    "Due to this periodicity, it does not make sense to average the phases because what will happen is that averaging $-\\pi$ and $\\pi$ phases together will result in a mean phase of zero, which is not what happens in reality.\n",
    "Fortunately there is a solution to this, which is called intertrial phase clustering (ITPC). The idea behind it is that we convert phases into vectors, that we can then sum and normalize. \n",
    "\n",
    "To transform a phase into a vector, we simply apply its exponential form: $e^{j\\phi}$\n",
    "\n",
    "How do we take into account the behavioral data now? Well, having the vectors in that form means they all have the same norm, which is 1. What we want to do it change their norm depending on the behavioral quantity we observe. We will therefore implement the following formula to compute the weighted ITPC:\n",
    "$$wITPC_t = |\\frac{\\sum_{i=1}^{n_{trials}} b_i e^{j \\phi_{i,t}}}{n_{trials} }|$$\n",
    "\n",
    ", where $i$ is the trial index, $b_i$ the response time at that trial, and $\\phi_{i,t}$ the phase at the considered time sample $t$ and at trial $i$. $n_{trials}$ is the total number of trials considered in the sum. The two bars mean that we are taking the absolute value.\n",
    "\n",
    "That yields one value of the wITPC per time sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009a5684",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_witpc_from_phase(phases, weights):\n",
    "    n=np.shape(phases)[0]\n",
    "    witpc=...#################################\n",
    "    return witpc\n",
    "\n",
    "witpc={}\n",
    "for f in freqs:\n",
    "    witpc[f]=compute_witpc_from_phase(phases[f],RT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b56cdd",
   "metadata": {},
   "source": [
    "Let's see what that looks like!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70a28db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_map(my_map, frequency):\n",
    "    fig, ax=plt.subplots(figsize=(12,5))\n",
    "    im=ax.pcolormesh(clean_epochs.times,clean_epochs.info['ch_names'],my_map)\n",
    "    ax.set_title(\"wITPC for {} frequencies\".format(frequency))\n",
    "    ax.set_xlabel('Time from stimulus (s)')\n",
    "    ax.set_ylabel('Channel')\n",
    "    fig.colorbar(im)\n",
    "    plt.show()\n",
    "\n",
    "from ipywidgets import widgets\n",
    "@widgets.interact(frequency=widgets.Dropdown(options=list(freqs.keys()),value='delta',description='Frequency',disabled=False))\n",
    "  \n",
    "def plot_witpc(frequency='delta'):\n",
    "    my_map=witpc[frequency]\n",
    "    display_map(my_map, frequency)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d8c598",
   "metadata": {},
   "source": [
    "You can now try to look at the different conditions separately. Do you see any difference in the wITPC for both conditions?\n",
    "\n",
    "Once this is done, you can also have a look at the test data, running the notebook. Are there any strong differences?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "010d59fe",
   "metadata": {},
   "source": [
    "## 5. Conclusion\n",
    "In this workshop, we have seen a technique that combines behavioral and neural recordings quite elegantly. In reality, there are additional steps that would be necessary to conclude on the link between phase and response times. Indeed, since both the phase and the response time can have an impact on the differences that we see, there should be a way to counteract individual effects to keep only combined effects. This is done through permutations: we shuffle the matching between phases and response times, recompute the wITPC, repeat this process several times and average the maps thus obtained to create the \"null hypothesis\", that is, create what maps would look like if the mapping between phase and response times were random.\n",
    "\n",
    "Since this needs some time to run and quite a lot of computer power, we do not do it during our workshop, but you are encouraged to try it at home!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc540f72",
   "metadata": {},
   "source": [
    "## 6. References and suggested reading\n",
    "Cohen, M. X. (2014). Analyzing neural time series data: theory and practice. Cambridge, Massachusetts: The MIT Press.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
